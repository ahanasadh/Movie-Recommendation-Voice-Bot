{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzfdDWk6JqSr",
        "outputId": "e4b127eb-27b9-4033-d6c7-9df52df1c3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_recommenders in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: scann in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: uuid in /usr/local/lib/python3.10/dist-packages (1.30)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_recommenders) (1.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_recommenders) (2.16.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scann) (1.25.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.43.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.9.0->tensorflow_recommenders) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow>=2.9.0->tensorflow_recommenders) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_recommenders scann uuid librosa ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qr09EXcJomb",
        "outputId": "41a53f1d-e455-4fb1-9245-42178043d93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-vvujh3h0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-vvujh3h0\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/Ahana/data.zip\n",
            "replace /content/ml-25m/ml-25m/ml-25m/genome-scores.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Ahana /content/ -r\n",
        "!unzip /content/Ahana/data.zip -d /content/ml-25m/\n",
        "!unzip /content/Ahana/1.zip -d /content/Labse/\n",
        "!unzip /content/Ahana/2.zip -d /content/Labse/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxUSPck6Jtw5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "EMBEDDING_SIZE = 128\n",
        "\n",
        "@keras.utils.register_keras_serializable(package=\"MyLayers\")\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        num_users=200000\n",
        "        num_movies=200000\n",
        "        embedding_size=128\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVISj1HhJkx8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class PersonalisedSearcher():\n",
        "    def __init__(self):\n",
        "        self.recommender = RecommenderNet()\n",
        "        self.recommender.load_weights('/content/Ahana/CF_Final.keras')\n",
        "        self.movies = pd.read_csv(\"/content/ml-25m/ml-25m/ml-25m/movies.csv\")\n",
        "        self.ratings = pd.read_csv(\"/content/ml-25m/ml-25m/ml-25m/ratings.csv\")\n",
        "        self.embeddings = pd.read_csv(\"/content/Ahana/data.csv\", index_col=0)\n",
        "        self.item_tensor = tf.convert_to_tensor(self.embeddings, dtype=tf.float32)\n",
        "        self.scann = tfrs.layers.factorized_top_k.ScaNN(num_leaves=1000, num_leaves_to_search = 100,\n",
        "                                                        k=round(np.sqrt(len(self.item_tensor))))\n",
        "        self.scann.index(self.item_tensor)\n",
        "        self.model = AutoModel.from_pretrained(\"./Labse\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"./Labse\")\n",
        "\n",
        "    def get_user_encodings(self):\n",
        "        user_ids = self.ratings[\"userId\"].unique().tolist()\n",
        "        user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "        userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "\n",
        "        return user2user_encoded, userencoded2user\n",
        "\n",
        "    def get_movie_encodings(self):\n",
        "        movie_ids = self.ratings[\"movieId\"].unique().tolist()\n",
        "        movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "        movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "\n",
        "        return movie2movie_encoded, movie_encoded2movie\n",
        "\n",
        "    def update_ratings(self):\n",
        "        user2user_encoded, _ = self.get_user_encodings()\n",
        "        movie2movie_encoded, _ = self.get_movie_encodings()\n",
        "        self.ratings[\"user\"] = self.ratings[\"userId\"].map(user2user_encoded)\n",
        "        self.ratings[\"movie\"] = self.ratings[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "        return self.ratings\n",
        "\n",
        "    def get_user_history(self, user_id):\n",
        "        df = self.update_ratings()\n",
        "        watched_movies = df[df.userId == user_id]\n",
        "\n",
        "    def get_candidate_movies(self, query):\n",
        "        encoded_input = self.tokenizer(query,\n",
        "                                  padding=True,\n",
        "                                  truncation=True,\n",
        "                                  max_length=64,\n",
        "                                  return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            model_output = self.model(**encoded_input)\n",
        "        query_embeddings = model_output.pooler_output\n",
        "        query_embeddings = torch.nn.functional.normalize(query_embeddings)\n",
        "        test_case = self.scann(np.array(query_embeddings))\n",
        "        return self.movies.iloc[test_case[1].numpy()[0]][0:11]\n",
        "\n",
        "    def filter_candidates(self, user_id, query):\n",
        "        movies_watched_by_user = self.ratings[self.ratings.userId == user_id]\n",
        "        candidates = self.get_candidate_movies(query)\n",
        "        movies_not_watched = candidates[\n",
        "            ~candidates[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "        ][\"movieId\"]\n",
        "        movie2movie_encoded, _ = self.get_movie_encodings()\n",
        "        movies_not_watched = list(set(movies_not_watched).\n",
        "                                  intersection(set(movie2movie_encoded.keys())))\n",
        "        movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "        user2user_encoded, _ = self.get_user_encodings()\n",
        "        user_encoder = user2user_encoded.get(user_id)\n",
        "        movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n",
        "\n",
        "        return movie_array, movies_not_watched, movies_watched_by_user\n",
        "\n",
        "    def personalised_search(self, user_id, query):\n",
        "        movie_array, movies_not_watched, movies_watched_by_user = self.filter_candidates(user_id, query)\n",
        "        scored_items = self.recommender.predict(movie_array).flatten()\n",
        "        top_rated = scored_items.argsort()[-10:][::-1]\n",
        "        _, movie_encoded2movie = self.get_movie_encodings()\n",
        "        recommended_movie_ids = [movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_rated]\n",
        "\n",
        "        return recommended_movie_ids, movies_watched_by_user\n",
        "\n",
        "    def print_recs(self, user_id, query):\n",
        "        recommendations, movies_watched_by_user = self.personalised_search(user_id, query)\n",
        "\n",
        "        print(\"Showing Top movie recommendations for user:\")\n",
        "        print(\"====\" * 9)\n",
        "        # print(\"Movies with high ratings from user\")\n",
        "        # print(\"----\" * 8)\n",
        "        # top_movies_user = (\n",
        "        #     movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "        #     .head(5)\n",
        "        #     .movieId.values\n",
        "        # )\n",
        "        # movie_df_rows = self.movies[self.movies[\"movieId\"].isin(top_movies_user)]\n",
        "        # for row in movie_df_rows.itertuples():\n",
        "        #     print(row.title, \":\", row.genres)\n",
        "        # print(\"----\" * 8)\n",
        "        # print(\"Top movie recommendations\")\n",
        "        # print(\"----\" * 8)\n",
        "        recommended_movies = self.movies[self.movies[\"movieId\"].isin(recommendations)]\n",
        "        for row in recommended_movies.itertuples():\n",
        "            print(row.title, \"\\t:\\t\", row.genres)\n",
        "        return recommended_movies.itertuples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75QzZuR2KG75"
      },
      "outputs": [],
      "source": [
        "!pip install gtts\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import whisper\n",
        "import gtts\n",
        "import uuid\n",
        "from IPython.display import Audio, display\n",
        "import wave\n",
        "import librosa\n",
        "\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=7):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  with open('audio.wav','wb') as f:\n",
        "    f.write(b)\n",
        "  return 'audio.wav'\n",
        "\n",
        "def transcribe(audio,model):\n",
        "  result = model.transcribe(audio,language=\"English\")\n",
        "  return result['text'].lower()\n",
        "\n",
        "def preprocess_query(query,wakeword):\n",
        "    query = query.lower()\n",
        "    query=query.replace(wakeword,\"\")\n",
        "    query = query.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    tokens = nltk.word_tokenize(query)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    query = \" \".join(tokens)\n",
        "    return query\n",
        "\n",
        "def textToSpeech(text):\n",
        "    tts = gtts.gTTS(text=text, lang='en')\n",
        "    name=str(uuid.uuid1())+'.wav'\n",
        "    tts.save(f\"./audios/{name}\")\n",
        "    display(Audio(f\"./audios/{name}\", autoplay=True))\n",
        "    time.sleep(librosa.get_duration(filename=f\"./audios/{name}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILpLsFhgQY_z"
      },
      "outputs": [],
      "source": [
        "print(\"Initializing Recommender Model\")\n",
        "searcher=PersonalisedSearcher()\n",
        "print(\"Initializing Whisper Model\")\n",
        "model = whisper.load_model(\"base\",in_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhDL-SwQNbzR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import time\n",
        "import random\n",
        "\n",
        "!rm ./audios -r\n",
        "!mkdir audios\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "wakeword=\"hello\"\n",
        "record_time=2\n",
        "query_record_time=7\n",
        "\n",
        "\n",
        "while True:\n",
        "  print(f\"\\n<<Listening for wake word 'hello'>>\\n\")\n",
        "  time.sleep(1)\n",
        "  audio=record(record_time)\n",
        "  text=transcribe(audio,model)\n",
        "  if text.count(wakeword) > 0:\n",
        "      display(Audio(\"./Ahana/hello.wav\", autoplay=True))\n",
        "      time.sleep(4)\n",
        "      print(f\"<<Now Listening for Query for {query_record_time} seconds>>\")\n",
        "      audio=record(query_record_time)\n",
        "      print(\"Now Transcribing\")\n",
        "      text=transcribe(audio,model)\n",
        "      print(\"\\n\"+text+\"\\n\")\n",
        "      print(\"Now Preprocessing\")\n",
        "      query=preprocess_query(text,\"\")\n",
        "      textToSpeech(\"Finding your movies. Please be patient\")\n",
        "      recommendations=searcher.print_recs(random.randrange(20, 50, 3),query)\n",
        "      rec_text=\"Here are some movies you might like.\"\n",
        "      for movie in recommendations:\n",
        "        rec_text+=\" \".join(movie.title.split(\" \")[:-1])+\". \"\n",
        "      print(\"\\n\\n\")\n",
        "      textToSpeech(rec_text)\n",
        "  else:\n",
        "      print(\"Wakeword Not Detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4uTIjn6N9yd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}